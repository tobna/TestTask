\documentclass[a4paper,onecolumn,oneside,11pt,english,bibliography=totoc]{article}
\usepackage[a4paper,left=25mm,right=25mm,top=20mm,bottom=20mm,marginpar=20mm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage[T1]{fontenc}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath, tabu}
\usepackage{amsxtra}
\usepackage{amsthm}
\usepackage{cancel}
\usepackage{dsfont}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{shapes}
\usepackage{mathcomp}
\usepackage{mathtools}
\usepackage{multirow}
\usepackage{verbatim}
\usepackage{polynom}
\usepackage{textcomp}
\usepackage[defaultlines=3,all]{nowidow}
\usepackage{float}
\usepackage{xcolor}
\usepackage{pdflscape}
\usepackage{csquotes}
\usepackage{setspace}
\usepackage{afterpage}
\usepackage{makecell}
% \usepackage[all]{xy}
\usepackage{listings}
\usepackage[hidelinks]{hyperref}
\usepackage{cleveref}
\usepackage{enumitem}
\usepackage{minibox}
\usepackage{algorithm}
\usepackage{pgfplots}
\usepackage{algpseudocode}
\usepackage{shuffle}

\usepgfplotslibrary{external} 
\tikzexternalize

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\setlength{\parindent}{0cm}%---------------------------------------------------------

\setnoclub[3]

\DeclareMathSymbol{\mlq}{\mathord}{operators}{``}
\DeclareMathSymbol{\mrq}{\mathord}{operators}{`'}

\newcommand{\R}{\mathbb R}
\newcommand{\N}{\mathbb N}
\newcommand{\calN}{\mathcal{N}}
\newcommand{\D}{\mathbb D}
\newcommand{\calD}{\mathcal D}
\newcommand{\C}{\mathbb C}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\A}{\mathcal A}
\newcommand{\B}{\mathcal B}
\newcommand{\I}{\mathcal I}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\M}{\mathcal{M}}
\renewcommand{\H}{\mathcal{H}}
\newcommand{\X}{\mathbb{X}}
\newcommand{\sigB}{\mathbb B}
\newcommand{\sigE}{\mathcal{E}}
\newcommand{\Ball}[2]{B_#1(#2)} % \Ball \eps center
\renewcommand{\L}{\mathcal{L}}
\newcommand{\eps}{\varepsilon}
\newcommand{\1}{\mathds{1}}
\newcommand{\To}{\longrightarrow}
\newcommand{\eqover}[1]{\stackrel{#1}{=}}
\newcommand{\darover}[1]{\xrightarrow{#1}}
\newcommand{\id}{\mathrm{id}}
\newcommand{\del}{\partial}
\newcommand{\indep}{\perp\!\!\!\perp}
\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\phi}{\varphi}
\renewcommand{\Im}{\operatorname{Im}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\mat}[4]{\begin{pmatrix}	#1 & #2 \\ #3 & #4 \end{pmatrix}}
\newcommand{\softmax}{\operatorname{softmax}}
\newcommand{\argmax}{\operatorname{argmax}}
\newcommand{\suff}{\operatorname{suff}}
\newcommand{\comp}{\operatorname{comp}}
\newcommand{\In}{\operatorname{In}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\tensor}{\otimes}
\newcommand{\bigtensor}{\bigotimes}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bB}{\mathbf{B}}
\newcommand{\grad}{\nabla}
\newcommand{\spanop}{\operatorname{span}}
\renewcommand{\S}{\mathcal{S}}
\newcommand{\Y}{\mathbb Y}
\newcommand{\Hoel}{\text{HÃ¶l}}
\newcommand{\Tau}{\mathcal{T}}
\newcommand{\W}{\mathcal{W}}
\newcommand{\emptyword}{\varnothing}



\newtheoremstyle{break}
{\topsep}{\topsep}%
{\upshape}{}%
{\bfseries}{:}%
{\newline}{}%

\newtheoremstyle{breakit}
{\topsep}{\topsep}%
{\itshape}{}%
{\bfseries}{:}%
{\newline}{}%

%%% Biber   
\usepackage[style=alphabetic]{biblatex}
\addbibresource{Literature.bib}
%\renewbibmacro*{name:andothers}{% Based on name:andothers from biblatex.def
%	\ifboolexpr{
%		test {\ifnumequal{\value{listcount}}{\value{liststop}}}
%		and
%		test \ifmorenames
%	}
%	{\ifnumgreater{\value{liststop}}{1}
%		{\finalandcomma}
%		{}
%		\andothersdelim\bibstring{et al}}
%	{}}

%\DeclareCiteCommand{\citeauthor}
%{\boolfalse{citetracker}%
%	\boolfalse{pagetracker}%
%	\usebibmacro{prenote}}
%{\ifciteindex
%	{\indexnames{labelname}}
%	{}%
%	\printtext[bibhyperref]{\printnames{labelname}}}
%{\multicitedelim}
%{\usebibmacro{postnote}}

\makeatletter
\newcommand{\newreptheorem}[2]{\newtheorem*{rep@#1}{\rep@title}\newenvironment{rep#1}[1]{\def\rep@title{#2 \ref*{##1}}\begin{rep@#1}}{\end{rep@#1}}}
\makeatother

\theoremstyle{breakit}
\newtheorem{thm}{Theorem}[section]
\newreptheorem{thm}{Theorem}
\newtheorem{lem}[thm]{Lemma}
\newtheorem*{lem*}{Lemma}
\newtheorem{cor}[thm]{Corollary}

\theoremstyle{break}
\newtheorem*{int*}{Intuition}
\newtheorem{rem}[thm]{Remark}
\newtheorem{definition}[thm]{Definition}
\newtheorem{notation}[thm]{Notation}
\newtheorem{ex}[thm]{Example}

\title{Report on the Test Task}

\author{
	Tobias Nauen
}
\date{\today}

\begin{document}
	\maketitle
	\section*{Experimental Setup}
	We trained a MobileNet-v2 with 10 classes on the first fold of the STL-10 dataset, using a LogSoftmax output, together with a negative log-likelihood loss. This first fold of data only consists of $1000$ labeled examples ($100$ for each of the $10$ classes). This model is then used to gather more training data from the $100 000$ unlabeled images. This is done by using the model's predictions as soft labels. Now, these labels are not perfect in any way; in fact, we expect them to be wrong for a lot of pictures. However, we can filter out the good labels by considering the model's confidence in its prediction. This is especially important in this case, as the unlabeled images come from a different distribution that even has more classes than the training examples. To create a balanced dataset from these soft-labeled examples, for each class we take $1000$ images that are soft-labeled as that class by the original model. These images are chosen on the highest maximum of the LogSoftmax/Softmax output, as a measure of model confidence. The reason for this is that for these images, the model is confident in its prediction, making it likely that the prediction is actually correct, while the unlabeled images, that are not in any of the original classes are likely to get a low score, since the model has not seen similar images before, making the output essentially random. We then take this new dataset of $10000$ images to train a new model (with the same architecture) and compare the resulting models on the STL-10 test set.
	
	\section*{Results}
	\begin{figure}[h]
	    \centering
	    \resizebox{\textwidth}{!}{\input{prior_train_data.pgf}}
	    \caption{Training progress of the prior model.}
	    \label{fig:training_prior}
	\end{figure}
	
	\begin{table}[h]
	    \centering
	    \scalebox{.95}{\begin{tabular}{c|cccccccccc}
	       Class & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
	       \hline
	       Relative size & 10\% & 10\% & 10\% & 10\% & 10\% & 10\% & 10\% & 10\% & 10\% & 10\%\\
	       Minimum confidence & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 
	    \end{tabular}}
	    \caption{Stats of the soft-labeled dataset of $10000$ images.}
	    \label{tab:soft_dataset_stats}
	\end{table}
	
	When training the first model, the training (top-1) accuracy quickly surges to over 95\% (as seen in \Cref{fig:training_prior}) and tops out at 100\%. This is expected, as the model can quickly overfit to the training data. On  the generation of the new dataset from the unlabeled images, the minimum confidence in any of the classes still was $1.0$, i.e. the model was sure in its predictions of all of these images.
	
	\begin{figure}[h]
	    \centering
	    \resizebox{\textwidth}{!}{\input{final_classifier_train_data.pgf}}
	    \caption{Training progress of the final classifier.}
	    \label{fig:training_classifier}
	\end{figure}
	
	The model trained on the new dataset also obtains a training accuracy of more than 95\%, but we expect it to generalize better to new, unseen images since it was trained on a bigger dataset.
	This is shown to be true when evaluating on the test set. Here, the original model obtains an accuracy of $33.74\%$, while the second model has an accuracy of $37.88\%$. This is an accuracy boost of more than 10\%.
	
	\section*{Conclusion}
	Semi-supervised learning, that is machine learning, where some labeled examples (supervised) and a lot of unlabeled examples (unsupervised) are given is a useful tool in machine learning, especially when there is no dataset of labeled training examples, that is big enough for a given model architecture. It can generate a lot of training data, using a weaker (possibly smaller) model at  first, which can then be used to train a larger classifier and therefore boost the classifier's accuracy. Semi-supervised learning relies on the fact, that examples without labels are much more common than labeled examples.
	
	When fine-tuning the original model on the new dataset, there would not be much of an improvement at all, since the model has no information to gain from the data. The examples are chosen, such that the model has high confidence (close to $1.0$). Therefore the loss on this dataset would be really small and no learning would happen. The new model, however, has not seen any images yet and therefore can learn using the new dataset. The new model then is likely to generalize better, since it was trained on a larger dataset, given the labeling error was sufficiently small.
	
\end{document}